{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOknmhIsUC4DLqCOcaUq8+r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kerriea-star/Distributed-training/blob/main/Custom_Training_Loops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tutorial demonstrates how to use `tf.distribute.Strategy`—a TensorFlow API that provides an abstraction for **distributing your training** across multiple processing units (GPUs, multiple machines, or TPUs)—with custom training loops. In this example, you will train a simple convolutional neural network on the **Fashion MNIST** dataset containing 70,000 images of size 28 x 28.\n",
        "\n",
        "**Custom training loops** provide flexibility and a greater control on training. They also make it easier to debug the model and the training loop."
      ],
      "metadata": {
        "id": "etSpnQm001iR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUftS19Of3Nw",
        "outputId": "b89f3fce-74b4-4657-eefe-6f4d65dfb1d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download the Fashion MNIST dataset"
      ],
      "metadata": {
        "id": "JLKfc_BY12mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Add a dimension to the array -> new shape == (28, 28, 1)\n",
        "# This is done because the first layer in our model is a convolutional\n",
        "# layer and it requires a 4D input (batch_size, height, width, channels).\n",
        "# batch_size dimension will be added later on.\n",
        "\n",
        "train_images = train_images[..., None]\n",
        "test_images = test_images[..., None]\n",
        "\n",
        "# Scale the images to the [0, 1] range.\n",
        "train_images = train_images / np.float32(255)\n",
        "test_images = test_images / np.float32(255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEVEBCkY1UXm",
        "outputId": "1b7334cf-7ce7-4cdc-a7ea-158f395baf2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create a strategy to distribute the variables and the graph\n",
        "\n",
        "How does `tf.distribute.MirroredStrategy` strategy work?\n",
        "\n",
        "*   All the variables and the model graph are replicated across the replicas.\n",
        "\n",
        "*   Input is evenly distributed across the replicas.\n",
        "\n",
        "*   Each replica calculates the loss and gradients for the input it received.\n",
        "\n",
        "*   The gradients are synced across all the replicas by **summing** them.\n",
        "\n",
        "*   After the sync, the same update is made to the copies of the variables on each replica.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AKWMM2kv3W4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If the list of devices is not specified in\n",
        "# `tf.distribute.MirroredStrategy` constructor, they will be auto-detected.\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "CdHG_lF622fQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWChEHWT4O2W",
        "outputId": "7eb13b7a-df30-4241-a946-6db7214ec668"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup input pipeline"
      ],
      "metadata": {
        "id": "ys9i7QoK49DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(train_images)\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "SWgonJo34dqj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the datasets and distribute them:"
      ],
      "metadata": {
        "id": "0SSHqVzP5W-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
        "\n",
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
      ],
      "metadata": {
        "id": "uLT7g0fW5Umt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create the model\n",
        "Create a model using `tf.keras.Sequential`. You can also use the **Model Subclassing API** or the **functional API** to do this."
      ],
      "metadata": {
        "id": "8OzNKAekmmLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  regularizer = tf.keras.regularizers.L2(1e-5)\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Conv2D(64, 3,\n",
        "                             activation='relu',\n",
        "                             kernel_regularizer=regularizer),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64,\n",
        "                            activation='relu',\n",
        "                            kernel_regularizer=regularizer),\n",
        "      tf.keras.layers.Dense(10, kernel_regularizer=regularizer)\n",
        "  ])\n",
        "\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "y7zbLfmF6Lv4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a checkpoint directory to store the checkpoints.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')"
      ],
      "metadata": {
        "id": "Ra5UcrFXnzAN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "beqqMfGQoFCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}